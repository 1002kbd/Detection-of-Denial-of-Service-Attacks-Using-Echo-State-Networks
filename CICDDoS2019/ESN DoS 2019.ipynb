{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # library that supports large and multi-dimensional arrays and matrices\n",
    "import pandas as pd # library for data manipulation and analysis\n",
    "import scipy.io # to read data from and write data to a variety of file formats\n",
    "from scipy import sparse # 2D sparse matrix package\n",
    "from sklearn.decomposition import PCA # linear dimensionality reduction\n",
    "from sklearn.linear_model import Ridge # linear least squares with L2 regularization\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from scipy.stats import zscore\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reservoir(object):\n",
    "    \"\"\"\n",
    "    Build a reservoir and evaluate internal states\n",
    "    \n",
    "    Parameters:\n",
    "        n_internal_units = processing units in the reservoir\n",
    "        spectral_radius = largest eigenvalue of the reservoir matrix of connection weights\n",
    "        leak = amount of leakage in the reservoir state update (optional)\n",
    "        connectivity = percentage of nonzero connection weights (unused in circle reservoir)\n",
    "        input_scaling = scaling of the input connection weights\n",
    "        noise_level = deviation of the Gaussian noise injected in the state update\n",
    "        circle = generate determinisitc reservoir with circle topology\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_internal_units=100, spectral_radius=0.99, leak=None,\n",
    "                 connectivity=0.3, input_scaling=0.2, noise_level=0.01, circle=False):\n",
    "        \n",
    "        # Initialize attributes\n",
    "        self._n_internal_units = n_internal_units\n",
    "        self._input_scaling = input_scaling\n",
    "        self._noise_level = noise_level\n",
    "        self._leak = leak\n",
    "\n",
    "        # Input weights depend on input size: they are set when data is provided\n",
    "        self._input_weights = None\n",
    "\n",
    "        # Generate internal weights\n",
    "        if circle:\n",
    "            self._internal_weights = self._initialize_internal_weights_Circ(\n",
    "                    n_internal_units,\n",
    "                    spectral_radius)\n",
    "        else:\n",
    "            self._internal_weights = self._initialize_internal_weights(\n",
    "                n_internal_units,\n",
    "                connectivity,\n",
    "                spectral_radius)\n",
    "\n",
    "\n",
    "    def _initialize_internal_weights_Circ(self, n_internal_units, spectral_radius):\n",
    "        \n",
    "        internal_weights = np.zeros((n_internal_units, n_internal_units))\n",
    "        internal_weights[0,-1] = spectral_radius\n",
    "        for i in range(n_internal_units-1):\n",
    "            internal_weights[i+1,i] = spectral_radius\n",
    "                \n",
    "        return internal_weights\n",
    "    \n",
    "    \n",
    "    def _initialize_internal_weights(self, n_internal_units,\n",
    "                                     connectivity, spectral_radius):\n",
    "\n",
    "        # Generate sparse, uniformly distributed weights.\n",
    "        internal_weights = sparse.rand(n_internal_units,\n",
    "                                       n_internal_units,\n",
    "                                       density=connectivity).todense()\n",
    "\n",
    "        # Ensure that the nonzero values are uniformly distributed in [-0.5, 0.5]\n",
    "        internal_weights[np.where(internal_weights > 0)] -= 0.5\n",
    "        \n",
    "        # Adjust the spectral radius.\n",
    "        E, _ = np.linalg.eig(internal_weights)\n",
    "        e_max = np.max(np.abs(E))\n",
    "        internal_weights /= np.abs(e_max)/spectral_radius       \n",
    "\n",
    "        return internal_weights\n",
    "\n",
    "\n",
    "    def _compute_state_matrix(self, X, n_drop=0):\n",
    "        N, T, _ = X.shape\n",
    "        previous_state = np.zeros((N, self._n_internal_units), dtype=float)\n",
    "\n",
    "        # Storage\n",
    "        state_matrix = np.empty((N, T - n_drop, self._n_internal_units), dtype=float)\n",
    "        for t in range(T):\n",
    "            current_input = X[:, t, :]\n",
    "\n",
    "            # Calculate state\n",
    "            state_before_tanh = self._internal_weights.dot(previous_state.T) + self._input_weights.dot(current_input.T)\n",
    "\n",
    "            # Add noise\n",
    "            state_before_tanh += np.random.rand(self._n_internal_units, N)*self._noise_level\n",
    "\n",
    "            # Apply nonlinearity and leakage (optional)\n",
    "            if self._leak is None:\n",
    "                previous_state = np.tanh(state_before_tanh).T\n",
    "            else:\n",
    "                previous_state = (1.0 - self._leak)*previous_state + np.tanh(state_before_tanh).T\n",
    "\n",
    "            # Store everything after the dropout period\n",
    "            if (t > n_drop - 1):\n",
    "                state_matrix[:, t - n_drop, :] = previous_state\n",
    "\n",
    "        return state_matrix\n",
    "\n",
    "\n",
    "    def get_states(self, X, n_drop=0, bidir=True):\n",
    "        N, T, V = X.shape\n",
    "        if self._input_weights is None:\n",
    "            self._input_weights = (2.0*np.random.binomial(1, 0.5 , [self._n_internal_units, V]) - 1.0)*self._input_scaling\n",
    "\n",
    "        # compute sequence of reservoir states\n",
    "        states = self._compute_state_matrix(X, n_drop)\n",
    "    \n",
    "        # reservoir states on time reversed input\n",
    "        if bidir is True:\n",
    "            X_r = X[:, ::-1, :]\n",
    "            states_r = self._compute_state_matrix(X_r, n_drop)\n",
    "            states = np.concatenate((states, states_r), axis=2)\n",
    "\n",
    "        return states\n",
    "    \n",
    "    def getReservoirEmbedding(self, X,pca, ridge_embedding,  n_drop=0, bidir=True, test = False):\n",
    "\n",
    "        res_states = self.get_states(X, n_drop=0, bidir=True)\n",
    "\n",
    "\n",
    "        N_samples = res_states.shape[0]\n",
    "        res_states = res_states.reshape(-1, res_states.shape[2])                   \n",
    "        # ..transform..\n",
    "        if test:\n",
    "            red_states = pca.transform(res_states)\n",
    "        else:\n",
    "            red_states = pca.fit_transform(res_states)          \n",
    "        # ..and put back in tensor form\n",
    "        red_states = red_states.reshape(N_samples,-1,red_states.shape[1])  \n",
    "\n",
    "        coeff_tr = []\n",
    "        biases_tr = []   \n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            ridge_embedding.fit(red_states[i, 0:-1, :], red_states[i, 1:, :])\n",
    "            coeff_tr.append(ridge_embedding.coef_.ravel())\n",
    "            biases_tr.append(ridge_embedding.intercept_.ravel())\n",
    "        #print(np.array(coeff_tr).shape,np.array(biases_tr).shape)\n",
    "        input_repr = np.concatenate((np.vstack(coeff_tr), np.vstack(biases_tr)), axis=1)\n",
    "        return input_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetify(s):\n",
    "    if s == 'BENIGN':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqArray(a,b):\n",
    "    return np.where(a == b, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdagi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (38,74) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Average Packet Size</th>\n",
       "      <th>Avg Bwd Segment Size</th>\n",
       "      <th>Avg Fwd Segment Size</th>\n",
       "      <th>Bwd Avg Bulk Rate</th>\n",
       "      <th>Bwd Avg Bytes/Bulk</th>\n",
       "      <th>...</th>\n",
       "      <th>Table Name</th>\n",
       "      <th>Time</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>BiFlowsCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2987377</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>274.285714</td>\n",
       "      <td>476.666667</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DrDoS_NTP.csv</td>\n",
       "      <td>2018-12-01 10:00:01 AM</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4290</td>\n",
       "      <td>1470</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987378</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.166667</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DrDoS_NTP.csv</td>\n",
       "      <td>2018-12-01 10:00:02 AM</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987379</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DrDoS_NTP.csv</td>\n",
       "      <td>2018-12-01 10:00:02 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DrDoS_NTP.csv</td>\n",
       "      <td>2018-12-01 10:00:02 AM</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DrDoS_NTP.csv</td>\n",
       "      <td>2018-12-01 10:00:05 AM</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DrDoS_NTP.csv</td>\n",
       "      <td>2018-12-01 9:59:57 AM</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987373</td>\n",
       "      <td>0</td>\n",
       "      <td>93489</td>\n",
       "      <td>77872.5</td>\n",
       "      <td>62256</td>\n",
       "      <td>22085.066097</td>\n",
       "      <td>29.894737</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DrDoS_NTP.csv</td>\n",
       "      <td>2018-12-01 9:59:57 AM</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>184</td>\n",
       "      <td>338</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DrDoS_NTP.csv</td>\n",
       "      <td>2018-12-01 9:59:59 AM</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DrDoS_NTP.csv</td>\n",
       "      <td>2018-12-01 9:59:59 AM</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DrDoS_NTP.csv</td>\n",
       "      <td>2018-12-01 9:59:59 AM</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5351835 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACK Flag Count  Active Max  Active Mean  Active Min    Active Std  \\\n",
       "2987377               1           0          0.0           0      0.000000   \n",
       "2987378               0           0          0.0           0      0.000000   \n",
       "2987379               0           0          0.0           0      0.000000   \n",
       "2987380               0           0          0.0           0      0.000000   \n",
       "2987381               0           0          0.0           0      0.000000   \n",
       "...                 ...         ...          ...         ...           ...   \n",
       "2987372               0           0          0.0           0      0.000000   \n",
       "2987373               0       93489      77872.5       62256  22085.066097   \n",
       "2987374               0           0          0.0           0      0.000000   \n",
       "2987375               0           0          0.0           0      0.000000   \n",
       "2987376               0           0          0.0           0      0.000000   \n",
       "\n",
       "         Average Packet Size  Avg Bwd Segment Size  Avg Fwd Segment Size  \\\n",
       "2987377           274.285714            476.666667            122.500000   \n",
       "2987378            27.166667             10.333333             33.666667   \n",
       "2987379             0.000000              0.000000              0.000000   \n",
       "2987380             0.000000              0.000000              0.000000   \n",
       "2987381             0.000000              0.000000              0.000000   \n",
       "...                      ...                   ...                   ...   \n",
       "2987372             0.000000              0.000000              0.000000   \n",
       "2987373            29.894737             30.666667             26.000000   \n",
       "2987374            40.000000              0.000000             30.800000   \n",
       "2987375            10.333333             12.400000              0.000000   \n",
       "2987376             0.000000              0.000000              0.000000   \n",
       "\n",
       "         Bwd Avg Bulk Rate  Bwd Avg Bytes/Bulk  ...     Table Name  \\\n",
       "2987377                  0                   0  ...  DrDoS_NTP.csv   \n",
       "2987378                  0                   0  ...  DrDoS_NTP.csv   \n",
       "2987379                  0                   0  ...  DrDoS_NTP.csv   \n",
       "2987380                  0                   0  ...  DrDoS_NTP.csv   \n",
       "2987381                  0                   0  ...  DrDoS_NTP.csv   \n",
       "...                    ...                 ...  ...            ...   \n",
       "2987372                  0                   0  ...  DrDoS_NTP.csv   \n",
       "2987373                  0                   0  ...  DrDoS_NTP.csv   \n",
       "2987374                  0                   0  ...  DrDoS_NTP.csv   \n",
       "2987375                  0                   0  ...  DrDoS_NTP.csv   \n",
       "2987376                  0                   0  ...  DrDoS_NTP.csv   \n",
       "\n",
       "                           Time  Total Backward Packets  Total Fwd Packets  \\\n",
       "2987377  2018-12-01 10:00:01 AM                       9                 12   \n",
       "2987378  2018-12-01 10:00:02 AM                       3                  3   \n",
       "2987379  2018-12-01 10:00:02 AM                       1                  1   \n",
       "2987380  2018-12-01 10:00:02 AM                       2                  1   \n",
       "2987381  2018-12-01 10:00:05 AM                       0                  2   \n",
       "...                         ...                     ...                ...   \n",
       "2987372   2018-12-01 9:59:57 AM                       2                  1   \n",
       "2987373   2018-12-01 9:59:57 AM                       6                 13   \n",
       "2987374   2018-12-01 9:59:59 AM                       0                  5   \n",
       "2987375   2018-12-01 9:59:59 AM                       5                  1   \n",
       "2987376   2018-12-01 9:59:59 AM                       2                  1   \n",
       "\n",
       "         Total Length of Bwd Packets  Total Length of Fwd Packets  \\\n",
       "2987377                         4290                         1470   \n",
       "2987378                           31                          101   \n",
       "2987379                            0                            0   \n",
       "2987380                            0                            0   \n",
       "2987381                            0                            0   \n",
       "...                              ...                          ...   \n",
       "2987372                            0                            0   \n",
       "2987373                          184                          338   \n",
       "2987374                            0                          154   \n",
       "2987375                           62                            0   \n",
       "2987376                            0                            0   \n",
       "\n",
       "         URG Flag Count  act_data_pkt_fwd  min_seg_size_forward  BiFlowsCount  \n",
       "2987377               0                 4                    32             1  \n",
       "2987378               1                 2                    20             3  \n",
       "2987379               1                 0                    32             3  \n",
       "2987380               1                 0                    32             3  \n",
       "2987381               1                 0                    32             1  \n",
       "...                 ...               ...                   ...           ...  \n",
       "2987372               1                 0                    32             3  \n",
       "2987373               1                 7                    20             3  \n",
       "2987374               1                 3                    20             3  \n",
       "2987375               1                 0                    20             3  \n",
       "2987376               1                 0                    20             3  \n",
       "\n",
       "[5351835 rows x 91 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('DDoS2019.csv')\n",
    "df2 = df1.groupby(['Time'])['Flow Duration'].count()\n",
    "df2 = pd.DataFrame(df2).reset_index()\n",
    "df2.columns=['Time','BiFlowsCount']\n",
    "df = df1.merge(df2, left_on='Time', right_on='Time')\n",
    "df = df.sort_values('Time')\n",
    "del df['Unnamed: 0']\n",
    "num_features = 20 # should be 10, 15, or 20\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Inbound', 'URG Flag Count', 'Bwd Packet Length Min', 'CWE Flag Count', 'min_seg_size_forward',\n",
    "           'BiFlowsCount', 'Destination Port', 'Source Port', 'RST Flag Count', 'ACK Flag Count', 'Down/Up Ratio', 'Init_Win_bytes_backward', \n",
    "           'Init_Win_bytes_forward', 'Bwd Packet Length Mean', 'Protocol', 'Avg Bwd Segment Size', 'Fwd PSH Flags',\n",
    "           'Fwd Packet Length Max', 'Fwd Packet Length Mean', 'Min Packet Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features[0:num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 features\n",
      "fraction:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdagi\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading X and y......\n",
      "X_train shape:(1070367, 15, 1) y_train shape:(1070367,)\n",
      "X_test shape:(267592, 15, 1) y_test shape:(267592,)\n"
     ]
    }
   ],
   "source": [
    "fraction = 0.125\n",
    "print(str(num_features) + \" features\")\n",
    "print(\"fraction:\" + str(fraction))\n",
    "data = df.sample(frac=fraction, replace=True, random_state=1)\n",
    "\n",
    "# get X and y. Normalize X and make it into 3D shape for reservoir\n",
    "num_col = data.shape[1]\n",
    "num_row = data.shape[0]\n",
    "\n",
    "X_data = data[features]\n",
    "X_data[features] = X_data[features].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "#norm_scaler = preprocessing.StandardScaler()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_data.values)\n",
    "X = np.nan_to_num(x_scaled)\n",
    "if len(X.shape) < 3:\n",
    "    X = np.atleast_3d(X)\n",
    "y = data['Label'].apply(targetify)\n",
    "print(\"Finished loading X and y......\")\n",
    "\n",
    "# split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "print(\"X_train shape:\" + str(X_train.shape), \"y_train shape:\" + str(y_train.shape))\n",
    "print(\"X_test shape:\" + str(X_test.shape), \"y_test shape:\" + str(y_test.shape))\n",
    "\n",
    "pca = PCA() #n_components gives number of components to keep for linear dimensionality reduction\n",
    "ridge_embedding = Ridge(alpha=10, fit_intercept=True)\n",
    "readout = Ridge(alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 internal units\n",
      "Finished loading training reservoir embedding......\n",
      "Finished loading testing reservoir embedding......\n",
      "        pred_class  true_class\n",
      "0              1.0           1\n",
      "178385         1.0           1\n",
      "178387         1.0           1\n",
      "178388         1.0           1\n",
      "178389         1.0           1\n",
      "178390         1.0           1\n",
      "178391         1.0           1\n",
      "178392         1.0           1\n",
      "178393         1.0           1\n",
      "178394         1.0           1\n"
     ]
    }
   ],
   "source": [
    "n=10 #number of internal units\n",
    "print(str(n) + \" internal units\")\n",
    "\n",
    "#run through reservoir\n",
    "res = Reservoir(n_internal_units=n, spectral_radius=0.9, leak=0.2,\n",
    "     connectivity=0.25, input_scaling=0.3, noise_level=0.01, circle=False)\n",
    "input_repr = res.getReservoirEmbedding(np.array(X_train), pca, ridge_embedding,  n_drop=0, bidir=False, test = False)\n",
    "print(\"Finished loading training reservoir embedding......\")\n",
    "input_repr_te = res.getReservoirEmbedding(np.array(X_test), pca, ridge_embedding,  n_drop=0, bidir=False, test = True)\n",
    "print(\"Finished loading testing reservoir embedding......\")\n",
    "\n",
    "#fit output\n",
    "readout.fit(input_repr, y_train)\n",
    "pred_class = readout.predict(input_repr_te)\n",
    "#predictions = [int(round(x)) for x in pred_class]\n",
    "true_class = list(y_test)\n",
    "\n",
    "#analysis\n",
    "compdf = pd.DataFrame({'pred_class':pred_class, 'true_class':true_class})\n",
    "compdf = compdf.sort_values('pred_class', ascending=False)\n",
    "print(str(compdf.head(10)))\n",
    "#compdf.to_csv(str(dataset.split('_')[0]) + '_' + str(fraction) + '_' + str(num_features) + '_' + str(n) + '.csv')\n",
    "#accuracy = np.sum(list(map(eqArray, predictions, true_class))) / len(true_class)\n",
    "#f1 = f1_score(true_class, predictions)\n",
    "#auc = roc_auc_score(true_class, predictions)\n",
    "\n",
    "#print(\"# of nonzero:\" + str(np.count_nonzero(predictions)))\n",
    "#print(\"accuracy is \" + str(accuracy))\n",
    "#print(\"f1 is \" + str(f1))\n",
    "#print(\"auc is \" + str(auc))\n",
    "#print(\"*******************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myRound(x, r):\n",
    "    if x>r/float(1000):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = list(compdf['pred_class'].apply(myRound, r=225))\n",
    "true_class = list(compdf['true_class'])\n",
    "accuracy = np.sum(list(map(eqArray, predictions, true_class))) / len(true_class)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myRound(x, r):\n",
    "    if x>r/float(1000):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[267592]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm = confusion_matrix(true_class, predictions)\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-eaa22c5e4ae0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confm.ravel()\n",
    "(tn + tp)/(tn+tp+fn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"False alarm rate is\")\n",
    "fp/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision is\")\n",
    "Precision = tp/(tp+fp)\n",
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall is\")\n",
    "Recall = tp/(tp+fn)\n",
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 is\")\n",
    "2*Precision*Recall/(Precision+Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
