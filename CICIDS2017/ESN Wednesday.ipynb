{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # library that supports large and multi-dimensional arrays and matrices\n",
    "import pandas as pd # library for data manipulation and analysis\n",
    "import scipy.io # to read data from and write data to a variety of file formats\n",
    "from scipy import sparse # 2D sparse matrix package\n",
    "from sklearn.decomposition import PCA # linear dimensionality reduction\n",
    "from sklearn.linear_model import Ridge # linear least squares with L2 regularization\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from scipy.stats import zscore\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reservoir(object):\n",
    "    \"\"\"\n",
    "    Build a reservoir and evaluate internal states\n",
    "    \n",
    "    Parameters:\n",
    "        n_internal_units = processing units in the reservoir\n",
    "        spectral_radius = largest eigenvalue of the reservoir matrix of connection weights\n",
    "        leak = amount of leakage in the reservoir state update (optional)\n",
    "        connectivity = percentage of nonzero connection weights (unused in circle reservoir)\n",
    "        input_scaling = scaling of the input connection weights\n",
    "        noise_level = deviation of the Gaussian noise injected in the state update\n",
    "        circle = generate determinisitc reservoir with circle topology\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_internal_units=100, spectral_radius=0.99, leak=None,\n",
    "                 connectivity=0.3, input_scaling=0.2, noise_level=0.01, circle=False):\n",
    "        \n",
    "        # Initialize attributes\n",
    "        self._n_internal_units = n_internal_units\n",
    "        self._input_scaling = input_scaling\n",
    "        self._noise_level = noise_level\n",
    "        self._leak = leak\n",
    "\n",
    "        # Input weights depend on input size: they are set when data is provided\n",
    "        self._input_weights = None\n",
    "\n",
    "        # Generate internal weights\n",
    "        if circle:\n",
    "            self._internal_weights = self._initialize_internal_weights_Circ(\n",
    "                    n_internal_units,\n",
    "                    spectral_radius)\n",
    "        else:\n",
    "            self._internal_weights = self._initialize_internal_weights(\n",
    "                n_internal_units,\n",
    "                connectivity,\n",
    "                spectral_radius)\n",
    "\n",
    "\n",
    "    def _initialize_internal_weights_Circ(self, n_internal_units, spectral_radius):\n",
    "        \n",
    "        internal_weights = np.zeros((n_internal_units, n_internal_units))\n",
    "        internal_weights[0,-1] = spectral_radius\n",
    "        for i in range(n_internal_units-1):\n",
    "            internal_weights[i+1,i] = spectral_radius\n",
    "                \n",
    "        return internal_weights\n",
    "    \n",
    "    \n",
    "    def _initialize_internal_weights(self, n_internal_units,\n",
    "                                     connectivity, spectral_radius):\n",
    "\n",
    "        # Generate sparse, uniformly distributed weights.\n",
    "        internal_weights = sparse.rand(n_internal_units,\n",
    "                                       n_internal_units,\n",
    "                                       density=connectivity).todense()\n",
    "\n",
    "        # Ensure that the nonzero values are uniformly distributed in [-0.5, 0.5]\n",
    "        internal_weights[np.where(internal_weights > 0)] -= 0.5\n",
    "        \n",
    "        # Adjust the spectral radius.\n",
    "        E, _ = np.linalg.eig(internal_weights)\n",
    "        e_max = np.max(np.abs(E))\n",
    "        internal_weights /= np.abs(e_max)/spectral_radius       \n",
    "\n",
    "        return internal_weights\n",
    "\n",
    "\n",
    "    def _compute_state_matrix(self, X, n_drop=0):\n",
    "        N, T, _ = X.shape\n",
    "        previous_state = np.zeros((N, self._n_internal_units), dtype=float)\n",
    "\n",
    "        # Storage\n",
    "        state_matrix = np.empty((N, T - n_drop, self._n_internal_units), dtype=float)\n",
    "        for t in range(T):\n",
    "            current_input = X[:, t, :]\n",
    "\n",
    "            # Calculate state\n",
    "            state_before_tanh = self._internal_weights.dot(previous_state.T) + self._input_weights.dot(current_input.T)\n",
    "\n",
    "            # Add noise\n",
    "            state_before_tanh += np.random.rand(self._n_internal_units, N)*self._noise_level\n",
    "\n",
    "            # Apply nonlinearity and leakage (optional)\n",
    "            if self._leak is None:\n",
    "                previous_state = np.tanh(state_before_tanh).T\n",
    "            else:\n",
    "                previous_state = (1.0 - self._leak)*previous_state + np.tanh(state_before_tanh).T\n",
    "\n",
    "            # Store everything after the dropout period\n",
    "            if (t > n_drop - 1):\n",
    "                state_matrix[:, t - n_drop, :] = previous_state\n",
    "\n",
    "        return state_matrix\n",
    "\n",
    "\n",
    "    def get_states(self, X, n_drop=0, bidir=True):\n",
    "        N, T, V = X.shape\n",
    "        if self._input_weights is None:\n",
    "            self._input_weights = (2.0*np.random.binomial(1, 0.5 , [self._n_internal_units, V]) - 1.0)*self._input_scaling\n",
    "\n",
    "        # compute sequence of reservoir states\n",
    "        states = self._compute_state_matrix(X, n_drop)\n",
    "    \n",
    "        # reservoir states on time reversed input\n",
    "        if bidir is True:\n",
    "            X_r = X[:, ::-1, :]\n",
    "            states_r = self._compute_state_matrix(X_r, n_drop)\n",
    "            states = np.concatenate((states, states_r), axis=2)\n",
    "\n",
    "        return states\n",
    "    \n",
    "    def getReservoirEmbedding(self, X,pca, ridge_embedding,  n_drop=0, bidir=True, test = False):\n",
    "\n",
    "        res_states = self.get_states(X, n_drop=0, bidir=True)\n",
    "\n",
    "        N_samples = res_states.shape[0]\n",
    "        res_states = res_states.reshape(-1, res_states.shape[2])                    \n",
    "        # ..transform..\n",
    "        if test:\n",
    "            red_states = pca.transform(res_states)\n",
    "        else:\n",
    "            red_states = pca.fit_transform(res_states)          \n",
    "        # ..and put back in tensor form\n",
    "        red_states = red_states.reshape(N_samples,-1,red_states.shape[1])\n",
    "        print(\"red_states:\" + str(red_states.shape))\n",
    "\n",
    "        coeff_tr = []\n",
    "        biases_tr = []   \n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            ridge_embedding.fit(red_states[i, 0:-1, :], red_states[i, 1:, :])\n",
    "            coeff_tr.append(ridge_embedding.coef_.ravel())\n",
    "            biases_tr.append(ridge_embedding.intercept_.ravel())\n",
    "        #print(np.array(coeff_tr).shape,np.array(biases_tr).shape)\n",
    "        input_repr = np.concatenate((np.vstack(coeff_tr), np.vstack(biases_tr)), axis=1)\n",
    "        return input_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetify(s):\n",
    "    if s == 'BENIGN':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqArray(a,b):\n",
    "    return np.where(a == b, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdagi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>target</th>\n",
       "      <th>BiFlowsCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>533819</td>\n",
       "      <td>52770</td>\n",
       "      <td>192.168.10.3-192.168.10.15-53-58098-17</td>\n",
       "      <td>192.168.10.15</td>\n",
       "      <td>58098</td>\n",
       "      <td>192.168.10.3</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>5/7/2017 10:00</td>\n",
       "      <td>181186</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>0</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533949</td>\n",
       "      <td>65256</td>\n",
       "      <td>192.168.10.1-192.168.10.3-53-60930-17</td>\n",
       "      <td>192.168.10.3</td>\n",
       "      <td>60930</td>\n",
       "      <td>192.168.10.1</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>5/7/2017 10:00</td>\n",
       "      <td>59693</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>0</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533948</td>\n",
       "      <td>600244</td>\n",
       "      <td>192.168.10.3-192.168.10.9-53-57312-17</td>\n",
       "      <td>192.168.10.9</td>\n",
       "      <td>57312</td>\n",
       "      <td>192.168.10.3</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>5/7/2017 10:00</td>\n",
       "      <td>280632</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>0</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533947</td>\n",
       "      <td>50849</td>\n",
       "      <td>172.16.0.1-192.168.10.50-54178-80-6</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>54178</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>5/7/2017 10:00</td>\n",
       "      <td>118013760</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.180000e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>118000000.0</td>\n",
       "      <td>118000000.0</td>\n",
       "      <td>DoS slowloris</td>\n",
       "      <td>1</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533946</td>\n",
       "      <td>52813</td>\n",
       "      <td>172.16.0.1-192.168.10.50-58374-80-6</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>58374</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>5/7/2017 10:00</td>\n",
       "      <td>3002965</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DoS slowloris</td>\n",
       "      <td>1</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602730</td>\n",
       "      <td>34148</td>\n",
       "      <td>192.168.10.14-104.88.37.207-50860-443-6</td>\n",
       "      <td>104.88.37.207</td>\n",
       "      <td>443</td>\n",
       "      <td>192.168.10.14</td>\n",
       "      <td>50860</td>\n",
       "      <td>6</td>\n",
       "      <td>5/7/2017 9:59</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>0</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602729</td>\n",
       "      <td>40899</td>\n",
       "      <td>192.168.10.3-192.168.10.5-123-123-17</td>\n",
       "      <td>192.168.10.5</td>\n",
       "      <td>123</td>\n",
       "      <td>192.168.10.3</td>\n",
       "      <td>123</td>\n",
       "      <td>17</td>\n",
       "      <td>5/7/2017 9:59</td>\n",
       "      <td>164</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>0</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602728</td>\n",
       "      <td>50836</td>\n",
       "      <td>172.16.0.1-192.168.10.50-58272-80-6</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>58272</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>5/7/2017 9:59</td>\n",
       "      <td>102589615</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.535367e+06</td>\n",
       "      <td>6414542.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1.920000e+07</td>\n",
       "      <td>1.880000e+07</td>\n",
       "      <td>51300000.0</td>\n",
       "      <td>5772658.0</td>\n",
       "      <td>DoS slowloris</td>\n",
       "      <td>1</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602744</td>\n",
       "      <td>34158</td>\n",
       "      <td>192.168.10.9-74.125.22.157-15619-443-6</td>\n",
       "      <td>192.168.10.9</td>\n",
       "      <td>15619</td>\n",
       "      <td>74.125.22.157</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>5/7/2017 9:59</td>\n",
       "      <td>5141382</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>0</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>601928</td>\n",
       "      <td>36224</td>\n",
       "      <td>192.168.10.14-23.201.74.154-50900-443-6</td>\n",
       "      <td>192.168.10.14</td>\n",
       "      <td>50900</td>\n",
       "      <td>23.201.74.154</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>5/7/2017 9:59</td>\n",
       "      <td>115542623</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>5.200211e+04</td>\n",
       "      <td>209389.0</td>\n",
       "      <td>36746.0</td>\n",
       "      <td>9.998048e+06</td>\n",
       "      <td>1.667248e+04</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>9949548.0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>0</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                  Flow ID      Source IP  \\\n",
       "533819       52770   192.168.10.3-192.168.10.15-53-58098-17  192.168.10.15   \n",
       "533949       65256    192.168.10.1-192.168.10.3-53-60930-17   192.168.10.3   \n",
       "533948      600244    192.168.10.3-192.168.10.9-53-57312-17   192.168.10.9   \n",
       "533947       50849      172.16.0.1-192.168.10.50-54178-80-6     172.16.0.1   \n",
       "533946       52813      172.16.0.1-192.168.10.50-58374-80-6     172.16.0.1   \n",
       "...            ...                                      ...            ...   \n",
       "602730       34148  192.168.10.14-104.88.37.207-50860-443-6  104.88.37.207   \n",
       "602729       40899     192.168.10.3-192.168.10.5-123-123-17   192.168.10.5   \n",
       "602728       50836      172.16.0.1-192.168.10.50-58272-80-6     172.16.0.1   \n",
       "602744       34158   192.168.10.9-74.125.22.157-15619-443-6   192.168.10.9   \n",
       "601928       36224  192.168.10.14-23.201.74.154-50900-443-6  192.168.10.14   \n",
       "\n",
       "         Source Port  Destination IP   Destination Port   Protocol  \\\n",
       "533819         58098    192.168.10.3                 53         17   \n",
       "533949         60930    192.168.10.1                 53         17   \n",
       "533948         57312    192.168.10.3                 53         17   \n",
       "533947         54178   192.168.10.50                 80          6   \n",
       "533946         58374   192.168.10.50                 80          6   \n",
       "...              ...             ...                ...        ...   \n",
       "602730           443   192.168.10.14              50860          6   \n",
       "602729           123    192.168.10.3                123         17   \n",
       "602728         58272   192.168.10.50                 80          6   \n",
       "602744         15619   74.125.22.157                443          6   \n",
       "601928         50900   23.201.74.154                443          6   \n",
       "\n",
       "             Timestamp   Flow Duration   Total Fwd Packets  ...    Active Std  \\\n",
       "533819  5/7/2017 10:00          181186                   4  ...  0.000000e+00   \n",
       "533949  5/7/2017 10:00           59693                   1  ...  0.000000e+00   \n",
       "533948  5/7/2017 10:00          280632                   2  ...  0.000000e+00   \n",
       "533947  5/7/2017 10:00       118013760                   2  ...  0.000000e+00   \n",
       "533946  5/7/2017 10:00         3002965                   3  ...  0.000000e+00   \n",
       "...                ...             ...                 ...  ...           ...   \n",
       "602730   5/7/2017 9:59              49                   2  ...  0.000000e+00   \n",
       "602729   5/7/2017 9:59             164                   2  ...  0.000000e+00   \n",
       "602728   5/7/2017 9:59       102589615                  14  ...  4.535367e+06   \n",
       "602744   5/7/2017 9:59         5141382                   5  ...  0.000000e+00   \n",
       "601928   5/7/2017 9:59       115542623                  20  ...  5.200211e+04   \n",
       "\n",
       "         Active Max   Active Min     Idle Mean      Idle Std     Idle Max  \\\n",
       "533819          0.0          0.0  0.000000e+00  0.000000e+00          0.0   \n",
       "533949          0.0          0.0  0.000000e+00  0.000000e+00          0.0   \n",
       "533948          0.0          0.0  0.000000e+00  0.000000e+00          0.0   \n",
       "533947         87.0         87.0  1.180000e+08  0.000000e+00  118000000.0   \n",
       "533946          0.0          0.0  0.000000e+00  0.000000e+00          0.0   \n",
       "...             ...          ...           ...           ...          ...   \n",
       "602730          0.0          0.0  0.000000e+00  0.000000e+00          0.0   \n",
       "602729          0.0          0.0  0.000000e+00  0.000000e+00          0.0   \n",
       "602728    6414542.0        565.0  1.920000e+07  1.880000e+07   51300000.0   \n",
       "602744          0.0          0.0  0.000000e+00  0.000000e+00          0.0   \n",
       "601928     209389.0      36746.0  9.998048e+06  1.667248e+04   10000000.0   \n",
       "\n",
       "           Idle Min          Label  target  BiFlowsCount  \n",
       "533819          0.0         BENIGN       0          1554  \n",
       "533949          0.0         BENIGN       0          1554  \n",
       "533948          0.0         BENIGN       0          1554  \n",
       "533947  118000000.0  DoS slowloris       1          1554  \n",
       "533946          0.0  DoS slowloris       1          1554  \n",
       "...             ...            ...     ...           ...  \n",
       "602730          0.0         BENIGN       0          1175  \n",
       "602729          0.0         BENIGN       0          1175  \n",
       "602728    5772658.0  DoS slowloris       1          1175  \n",
       "602744          0.0         BENIGN       0          1175  \n",
       "601928    9949548.0         BENIGN       0          1175  \n",
       "\n",
       "[800000 rows x 88 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('oversampled_CICIDS2017_Wed.csv')\n",
    "df2 = df1.groupby([' Timestamp'])[' Flow Duration'].count()\n",
    "df2 = pd.DataFrame(df2).reset_index()\n",
    "df2.columns=[' Timestamp','BiFlowsCount']\n",
    "df = df1.merge(df2, left_on=' Timestamp', right_on=' Timestamp')\n",
    "df = df.sort_values(' Timestamp')\n",
    "num_features = 20 # should be 10, 15, or 20\n",
    "features_ = ['BiFlowsCount', ' Protocol', ' ACK Flag Count', 'Idle Mean', ' Bwd Packet Length Mean', ' Flow IAT Max', ' Destination Port', \n",
    "             ' Avg Bwd Segment Size', ' Packet Length Std', ' Idle Max', ' Average Packet Size', ' Packet Length Mean', ' Fwd IAT Max', ' Source Port',\n",
    "            ' min_seg_size_forward', ' Bwd Packet Length Std', ' Min Packet Length', ' URG Flag Count', 'Bwd Packet Length Max', ' Fwd IAT Std']\n",
    "features = features_[0:num_features]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow ID', ' Source IP', ' Source Port', ' Destination IP',\n",
       "       ' Destination Port', ' Protocol', ' Timestamp', ' Flow Duration',\n",
       "       ' Total Fwd Packets', ' Total Backward Packets',\n",
       "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
       "       ' Fwd Packet Length Max', ' Fwd Packet Length Min',\n",
       "       ' Fwd Packet Length Mean', ' Fwd Packet Length Std',\n",
       "       'Bwd Packet Length Max', ' Bwd Packet Length Min',\n",
       "       ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s',\n",
       "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
       "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
       "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
       "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags',\n",
       "       ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags',\n",
       "       ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s',\n",
       "       ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n",
       "       ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance',\n",
       "       'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n",
       "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
       "       ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n",
       "       ' Average Packet Size', ' Avg Fwd Segment Size',\n",
       "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n",
       "       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n",
       "       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
       "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
       "       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n",
       "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n",
       "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
       "       ' Idle Max', ' Idle Min', ' Label', 'BiFlowsCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['target']\n",
    "del df['Unnamed: 0']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 features\n",
      "fraction:0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdagi\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading X and y......\n",
      "X_train shape:(320000, 20, 1) y_train shape:(320000,)\n",
      "X_test shape:(80000, 20, 1) y_test shape:(80000,)\n"
     ]
    }
   ],
   "source": [
    "fraction = 0.5\n",
    "print(str(num_features) + \" features\")\n",
    "print(\"fraction:\" + str(fraction))\n",
    "data = df.sample(frac=fraction, replace=True, random_state=1)\n",
    "\n",
    "# get X and y. Normalize X and make it into 3D shape for reservoir\n",
    "num_col = data.shape[1]\n",
    "num_row = data.shape[0]\n",
    "\n",
    "X_data = data[features]\n",
    "X_data[features] = X_data[features].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "#norm_scaler = preprocessing.StandardScaler()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_data.values)\n",
    "X = np.nan_to_num(x_scaled)\n",
    "if len(X.shape) < 3:\n",
    "    X = np.atleast_3d(X)\n",
    "y = data[' Label'].apply(targetify)\n",
    "print(\"Finished loading X and y......\")\n",
    "\n",
    "# split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "print(\"X_train shape:\" + str(X_train.shape), \"y_train shape:\" + str(y_train.shape))\n",
    "print(\"X_test shape:\" + str(X_test.shape), \"y_test shape:\" + str(y_test.shape))\n",
    "\n",
    "pca = PCA() #n_components gives number of components to keep for linear dimensionality reduction\n",
    "ridge_embedding = Ridge(alpha=10, fit_intercept=True)\n",
    "readout = Ridge(alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 internal units\n",
      "red_states:(320000, 20, 60)\n",
      "Finished loading training reservoir embedding......\n",
      "red_states:(80000, 20, 60)\n",
      "Finished loading testing reservoir embedding......\n",
      "       pred_class  true_class\n",
      "56898    1.359128           1\n",
      "60946    1.348427           1\n",
      "49747    1.296080           1\n",
      "43117    1.295769           1\n",
      "40929    1.292817           1\n",
      "9850     1.291667           1\n",
      "4570     1.282292           1\n",
      "35094    1.272470           1\n",
      "51012    1.267673           1\n",
      "35840    1.267554           1\n"
     ]
    }
   ],
   "source": [
    "n=30 #number of internal units\n",
    "print(str(n) + \" internal units\")\n",
    "\n",
    "#run through reservoir\n",
    "res = Reservoir(n_internal_units=n, spectral_radius=0.9, leak=0.2,\n",
    "     connectivity=0.25, input_scaling=0.3, noise_level=0.01, circle=False)\n",
    "input_repr = res.getReservoirEmbedding(np.array(X_train), pca, ridge_embedding,  n_drop=0, bidir=False, test = False)\n",
    "print(\"Finished loading training reservoir embedding......\")\n",
    "input_repr_te = res.getReservoirEmbedding(np.array(X_test), pca, ridge_embedding,  n_drop=0, bidir=False, test = True)\n",
    "print(\"Finished loading testing reservoir embedding......\")\n",
    "\n",
    "#fit output\n",
    "readout.fit(input_repr, y_train)\n",
    "pred_class = readout.predict(input_repr_te)\n",
    "#predictions = [int(round(x)) for x in pred_class]\n",
    "true_class = list(y_test)\n",
    "\n",
    "#analysis\n",
    "compdf = pd.DataFrame({'pred_class':pred_class, 'true_class':true_class})\n",
    "compdf = compdf.sort_values('pred_class', ascending=False)\n",
    "print(str(compdf.head(10)))\n",
    "#compdf.to_csv(str(dataset.split('_')[0]) + '_' + str(fraction) + '_' + str(num_features) + '_' + str(n) + '.csv')\n",
    "#accuracy = np.sum(list(map(eqArray, predictions, true_class))) / len(true_class)\n",
    "#f1 = f1_score(true_class, predictions)\n",
    "#auc = roc_auc_score(true_class, predictions)\n",
    "\n",
    "#print(\"# of nonzero:\" + str(np.count_nonzero(predictions)))\n",
    "#print(\"accuracy is \" + str(accuracy))\n",
    "#print(\"f1 is \" + str(f1))\n",
    "#print(\"auc is \" + str(auc))\n",
    "#print(\"*******************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myRound(x, r):\n",
    "    if x>r/float(1000):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97115"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = list(compdf['pred_class'].apply(myRound, r=225))\n",
    "true_class = list(compdf['true_class'])\n",
    "accuracy = np.sum(list(map(eqArray, predictions, true_class))) / len(true_class)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myRound(x, r):\n",
    "    if x>r/float(1000):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37866,  2095],\n",
       "       [  213, 39826]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm = confusion_matrix(true_class, predictions)\n",
    "confm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97115"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confm.ravel()\n",
    "(tn + tp)/(tn+tp+fn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False alarm rate is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.052426115462576015"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"False alarm rate is\")\n",
    "fp/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9500250471124257"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Precision is\")\n",
    "Precision = tp/(tp+fp)\n",
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9946801868178526"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Recall is\")\n",
    "Recall = tp/(tp+fn)\n",
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9718399219131284"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"F1 is\")\n",
    "2*Precision*Recall/(Precision+Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
